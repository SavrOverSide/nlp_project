{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f8ba84-ef74-4c90-8347-ca23adb01975",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "276f96d9-8118-4b24-9c42-071e58988892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#### Word2Vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "####\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchutils as tu\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "from src.rnn_preprocessing import (\n",
    "                                data_preprocessing, \n",
    "                                preprocess_single_string, \n",
    "                                padding, \n",
    "                                get_words_by_freq\n",
    "                                )\n",
    "from src.train_rnn import train_attention_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dbb499e2-1580-478a-b719-f41d0713dc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3.2\n"
     ]
    }
   ],
   "source": [
    "# Лучше всего установить такую же версию\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da6d9566-f6ae-44bf-98f2-35bc8722a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Укажите путь к вашему .jsonl файлу\n",
    "file_path = '/home/savr/nlp_project/healthcare_facilities_reviews.jsonl'\n",
    "\n",
    "# Чтение файла и загрузка данных в список\n",
    "data = []\n",
    "with open(file_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "# Преобразование списка словарей в DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "reviews = df['content'].tolist()\n",
    "preprocessed = [data_preprocessing(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d5932c8-c7f8-48c6-81a3-02e731d270d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'почему мы простые граждане должны быть в ответе за то что в данной поликлиники не было воды мало того что запись идет день в день с часов а по телефону ли по непонятной причине принять заявку тоже отказываются так еще и наплевательское отношение к людям в регистратуре легче всего видите ли отфудболить пациента на следующий день и никакого решения взамен какоето безразличие и непонимание проблем детей такие люди просто не должны находиться на данных местах так как это в первую очередь социальная ответственность тем более перед детьми'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1c6c1145-02d9-4d33-8931-5adf0dc5d0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('сотрудница', 201),\n",
       " ('прав', 201),\n",
       " ('методы', 201),\n",
       " ('спас', 201),\n",
       " ('внизу', 201),\n",
       " ('страшное', 201),\n",
       " ('письмо', 201),\n",
       " ('исследований', 201),\n",
       " ('младший', 201),\n",
       " ('беременные', 201)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Анализируем частоты слов и выбираем только те, которые встречаются чаще порога\n",
    "corpus = [word for text in preprocessed for word in text.split()]\n",
    "sorted_words = Counter(corpus).most_common()\n",
    "sorted_words = get_words_by_freq(sorted_words, 200)\n",
    "sorted_words[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f88157e1-e993-42cb-82ae-fa6e113e918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем словарь слово: индекс\n",
    "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
    "# vocab_to_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "955a4a1f-468d-4768-abcd-a032753398af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open('vocab2int.json', 'w') as f:\n",
    "    json.dump(vocab_to_int, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cfe9c308-1479-44bf-81f9-bbdf56ffd3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_txt = ','.join([str(i) for i in stop_words])\n",
    "with open('stop_words.txt', 'w') as f:\n",
    "    f.write(stop_words_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9434a36e-6d0d-4f69-9054-637a7632965c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('и', 1),\n",
       " ('в', 2),\n",
       " ('не', 3),\n",
       " ('на', 4),\n",
       " ('что', 5),\n",
       " ('я', 6),\n",
       " ('с', 7),\n",
       " ('к', 8),\n",
       " ('а', 9),\n",
       " ('у', 10)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vocab_to_int.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fae4f6e6-932e-43b6-83dd-dbd032ab3fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80, 20, 11, 850, 648, 389, 1231, 11, 98, 559, 7, 371, 874, 802, 613, 18, 12, 1006, 1, 6, 1758, 4, 850, 95, 1, 1145, 369, 58, 211, 1, 2132, 13, 349]\n",
      "огромное спасибо за чудесное удаление двух зубов мудрости за мгновение доктор матвеев профессионал с большой буквы боялась страшно но все заняло реально секунд и я согласилась на удаление сразу и второго зуба без боли и страха очень рекомендую\n"
     ]
    }
   ],
   "source": [
    "# Конвертируем слова в индексы\n",
    "reviews_int = []\n",
    "for text in preprocessed:\n",
    "    r = [vocab_to_int[word] for word in text.split() if vocab_to_int.get(word)]\n",
    "    reviews_int.append(r)\n",
    "print([i for i in reviews_int[0]])\n",
    "print(preprocessed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0beb3358-cad4-461b-86c2-d608f055286b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 70597\n",
      "Random review for word2vec: ['я', 'лечилась', 'в', 'в', 'августе', 'того', 'года', 'мне', 'полностью', 'сделали', 'зубов', 'скажу', 'сразу', 'что', 'во', 'всех', 'остальных', 'клиниках', 'мне', 'ставить', 'коронки', 'и', 'даже', 'никто', 'не', 'хотел', 'мне', 'помочь', 'но', 'мне', 'очень', 'повезло', 'что', 'моим', 'доктором', 'оказалась', 'наталья', 'михайловна', 'врач', 'от', 'бога', 'специалист', 'я', 'до', 'сих', 'пор', 'хожу', 'к', 'ней', 'лечиться', 'и', 'очень', 'довольна', 'спасибо', 'ей', 'огромное', 'хожу', 'с', 'улыбкой', 'да', 'конечно', 'цены', 'в', 'данной', 'организации', 'не', 'самые', 'маленькие', 'но', 'мне', 'все', 'рано', 'обошлось', 'дешевле', 'чем', 'бы', 'мне', 'поставили', 'коронки', 'и', 'вообще', 'за', 'такую', 'работу', 'можно', 'заплатить', 'у', 'меня', 'с', 'работы', 'многие', 'девушки', 'обращались', 'с', 'наталье', 'михайловне', 'и', 'все', 'были', 'довольны', 'спасибо', 'вам']\n"
     ]
    }
   ],
   "source": [
    "w2v_input = []\n",
    "for review in preprocessed:\n",
    "    cur_review = []\n",
    "    for word in review.split():\n",
    "        if vocab_to_int.get(word):\n",
    "            cur_review.append(word)\n",
    "    w2v_input.append(cur_review)\n",
    "print(f'Total reviews: {len(w2v_input)}')\n",
    "print(f'Random review for word2vec: {w2v_input[np.random.randint(0, 50000)]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46575ff8-96f8-4c51-a5d0-8cb0a93f82e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab_to_int) + 1  # размер словаря вместе с токеном padding\n",
    "EMBEDDING_DIM = 64 # embedding_dim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d6c4b429-e32f-4daa-9e9b-9dfbff798309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reviews: 70597\n"
     ]
    }
   ],
   "source": [
    "# Обучим Word2Vec\n",
    "wv = Word2Vec(\n",
    "    vector_size=EMBEDDING_DIM # размерность вектора для слова\n",
    "    )\n",
    "# Сначала word2vec составляет словарь\n",
    "wv.build_vocab(w2v_input)\n",
    "print(f'Total reviews: {wv.corpus_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "44faa574-7e94-4f1c-a063-24df8bd35fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39359172, 50573400)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Далее обучаем\n",
    "wv.train(\n",
    "    corpus_iterable=w2v_input, \n",
    "    total_examples=wv.corpus_count, \n",
    "    epochs=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ece70155-6611-4696-a244-e3737e498e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words x EMEDDING_DIM: (3305, 64)\n"
     ]
    }
   ],
   "source": [
    "# Создаем слой эмбеддинга\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, EMBEDDING_DIM))\n",
    "\n",
    "# Бежим по всем словам словаря: если слово есть в word2vec, \n",
    "# достаем его вектор; если слова нет, то распечатываем его и пропускаем\n",
    "for word, i in vocab_to_int.items():\n",
    "    try:\n",
    "        embedding_vector = wv.wv[word]\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    except KeyError as e:\n",
    "        pass\n",
    "        print(f'{e}: word: {word}')\n",
    "        \n",
    "# Создаем предобученный эмбеддинг – этот слой в нашей сети обучаться не будет\n",
    "embedding_layer = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix))\n",
    "print(f'Number of words x EMEDDING_DIM: {embedding_matrix.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e4051ad4-52b4-4548-be39-330223cefd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 127   20 2025 2600    6   13  409  422  968   61    7  371  874  311\n",
      " 1116   93  190 1259 2487  369    2  154   14   23 2710    2  164  661\n",
      "  317    6  358    1   14   17    3 1981 2025 2600   32  260    2  184\n",
      "   12 1267  397   85   32  895    1   58  187  280  247  278  380  206\n",
      "    1    2   90 3234  876 1637 2875   12]\n"
     ]
    }
   ],
   "source": [
    "# Применяем padding\n",
    "padded = padding(review_int=reviews_int, seq_len=64)\n",
    "print(padded[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f0360b4-ec11-419a-842b-4fff7275d680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test split + label encoding \n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    np.array(padded),\n",
    "    pd.get_dummies(\n",
    "        df['sentiment'], \n",
    "        drop_first=True\n",
    "    ).values.astype('int'), test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "90c9d214-7923-4348-8781-aef6d2283eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "train_data = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(y_train))\n",
    "valid_data = TensorDataset(torch.from_numpy(X_valid), torch.from_numpy(y_valid))\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=BATCH_SIZE)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b3cfe3a-b522-4f2f-b704-fa9de3120ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input size: BATCH_SIZE x SEQ_LEN torch.Size([64, 64])\n",
      "Sample input: \n",
      " tensor([[   0,    0,    0,  ...,  127,   31,   20],\n",
      "        [   6,   44, 2593,  ...,   14, 1044,  308],\n",
      "        [  76, 1573,  407,  ...,    6,    2, 1740],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ..., 2547,   14,   13],\n",
      "        [ 124,    2,  164,  ...,    1, 3268,    6],\n",
      "        [   0,    0,    0,  ...,  294,   20,   31]])\n",
      "Sample input: \n",
      " tensor([[1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [0],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1],\n",
      "        [1]])\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, что внутри\n",
    "dataiter = iter(train_loader)\n",
    "sample_x, sample_y = next(dataiter)\n",
    "\n",
    "print('Sample input size: BATCH_SIZE x SEQ_LEN', sample_x.size()) # batch_size, seq_length\n",
    "print('Sample input: \\n', sample_x)\n",
    "print('Sample input: \\n', sample_y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51cb6453-e5b1-498e-8852-90c538f73389",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "43d89410-f2f7-4fd8-9b37-61a57ddd528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a95f010-4f55-4fd5-b1f4-8eec5fa113b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 128])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConcatAttention(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            hidden_size: int = HIDDEN_SIZE\n",
    "            ) -> None:\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.linear = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.align  = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.tanh   = nn.Tanh()\n",
    "\n",
    "    def forward(\n",
    "            self, \n",
    "            lstm_outputs: torch.Tensor, # BATCH_SIZE x SEQ_LEN x HIDDEN_SIZE\n",
    "            final_hidden: torch.Tensor  # BATCH_SIZE x HIDDEN_SIZE\n",
    "            ) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        \n",
    "        att_weights = self.linear(lstm_outputs)\n",
    "        # print(f'After linear: {att_weights.shape, final_hidden.unsqueeze(2).shape}')\n",
    "        att_weights = torch.bmm(att_weights, final_hidden.unsqueeze(2))\n",
    "        # print(f'After bmm: {att_weights.shape}')\n",
    "        att_weights = F.softmax(att_weights.squeeze(2), dim=1)\n",
    "        # print(f'After softmax: {att_weights.shape}')\n",
    "        cntxt       = torch.bmm(lstm_outputs.transpose(1, 2), att_weights.unsqueeze(2))\n",
    "        # print(f'Context: {cntxt.shape}')\n",
    "        concatted   = torch.cat((cntxt, final_hidden.unsqueeze(2)), dim=1)\n",
    "        # print(f'Concatted: {concatted.shape}')\n",
    "        att_hidden  = self.tanh(self.align(concatted.squeeze(-1)))\n",
    "        # print(f'Att Hidden: {att_hidden.shape}')\n",
    "        return att_hidden, att_weights\n",
    "\n",
    "# Test on random numbers\n",
    "ConcatAttention()(torch.randn(BATCH_SIZE, 128, HIDDEN_SIZE), torch.randn(BATCH_SIZE, HIDDEN_SIZE))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c3628285-ee47-4c1b-be8e-6fc48f6adee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = ConcatAttention(HIDDEN_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5a4954a2-2f5b-42b6-993c-6d33522cee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======================================================\n",
      "Layer       Kernel       Output      Params       FLOPs\n",
      "=======================================================\n",
      "0_linear   [32, 32]   [16, 32, 32]    1,056   1,032,192\n",
      "1_align    [64, 32]       [16, 32]    2,080      65,024\n",
      "2_tanh            -       [16, 32]        0       2,560\n",
      "=======================================================\n",
      "Total params: 3,136\n",
      "Trainable params: 3,136\n",
      "Non-trainable params: 0\n",
      "Total FLOPs: 1,099,776 / 1.10 MFLOPs\n",
      "-------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 0.13\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 0.21\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "tu.get_model_summary(attention, torch.randn(16, 32, HIDDEN_SIZE), torch.randn(16, HIDDEN_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9478950c-ab43-4a66-95e9-a2d8cf8532e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fd641319-e957-4f2c-ac20-87737c6e5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMConcatAttention(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # self.embedding = nn.Embedding(VOCAB_SIZE, EMBEDDING_DIM)\n",
    "        self.embedding = embedding_layer\n",
    "        self.lstm = nn.LSTM(EMBEDDING_DIM, HIDDEN_SIZE, batch_first=True)\n",
    "        self.attn = ConcatAttention(HIDDEN_SIZE)\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_SIZE, 128),\n",
    "            nn.Dropout(),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        embeddings = self.embedding(x)\n",
    "        outputs, (h_n, _) = self.lstm(embeddings)\n",
    "        att_hidden, att_weights = self.attn(outputs, h_n.squeeze(0))\n",
    "        out = self.clf(att_hidden)\n",
    "        return out, att_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2072c697-d514-483a-8978-b4d6d7f3f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_concat = LSTMConcatAttention()\n",
    "DEVICE='cuda'\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer_concat = torch.optim.RMSprop(model_concat.parameters(), lr=0.001)\n",
    "\n",
    "metric = BinaryAccuracy() #BinaryAccuracy().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fbc1b525-03a5-4247-899f-dc48a217d273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.2429 val_loss : 0.2355\n",
      "train_accuracy : 0.90 val_accuracy : 0.91\n",
      "==================================================\n",
      "Epoch 2\n",
      "train_loss : 0.2060 val_loss : 0.2221\n",
      "train_accuracy : 0.92 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 3\n",
      "train_loss : 0.1895 val_loss : 0.2417\n",
      "train_accuracy : 0.93 val_accuracy : 0.91\n",
      "==================================================\n",
      "Epoch 4\n",
      "train_loss : 0.1775 val_loss : 0.2205\n",
      "train_accuracy : 0.93 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 5\n",
      "train_loss : 0.1662 val_loss : 0.2133\n",
      "train_accuracy : 0.94 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 6\n",
      "train_loss : 0.1566 val_loss : 0.2505\n",
      "train_accuracy : 0.94 val_accuracy : 0.91\n",
      "==================================================\n",
      "Epoch 7\n",
      "train_loss : 0.1481 val_loss : 0.2182\n",
      "train_accuracy : 0.95 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 8\n",
      "train_loss : 0.1401 val_loss : 0.2377\n",
      "train_accuracy : 0.95 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 9\n",
      "train_loss : 0.1314 val_loss : 0.2446\n",
      "train_accuracy : 0.95 val_accuracy : 0.92\n",
      "==================================================\n",
      "Epoch 10\n",
      "train_loss : 0.1239 val_loss : 0.2513\n",
      "train_accuracy : 0.96 val_accuracy : 0.92\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses, train_metric, val_metric, rnn_time = train_attention_lstm(\n",
    "    10, model_concat, train_loader, valid_loader, optimizer_concat, criterion, metric\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "70398c28-3f58-433d-b5c9-0e142c88fea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_to_int['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c6114d8-d445-4ec5-9eb3-790b4ab8f0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_to_vocab = {j:i for i, j in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b9a5a7f1-a316-4319-8545-f0fdc792c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_predict(review: str, SEQ_LEN: int, model: nn.Module):\n",
    "    \"\"\"Predict class and draw word attention scores \n",
    "\n",
    "    Args:\n",
    "        review (str): Review text\n",
    "        SEQ_LEN (int): sequence length\n",
    "        model (nn.Module): trained model\n",
    "    \"\"\"\n",
    "    preprocessed = data_preprocessing(review) # preprocess string\n",
    "    inp = preprocess_single_string(review, SEQ_LEN, vocab_to_int)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        pred, att_scores = model(inp.long().unsqueeze(0))\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    print(f'Prepocessed string: {preprocessed}')\n",
    "    print(f'Prediction {pred.sigmoid().item():.3f}')\n",
    "    print(max(att_scores.detach().cpu().numpy()[0]))\n",
    "    plt.bar(np.arange(len(inp)), att_scores.detach().cpu().numpy()[0])\n",
    "    plt.ylim(0, max(att_scores.detach().cpu().numpy()[0])+.2)\n",
    "    plt.xticks(\n",
    "        ticks = np.arange(len(inp)), \n",
    "        labels = [int_to_vocab[x.item()] for x in inp]\n",
    "        );\n",
    "    score_label_shift = len(inp)*.02\n",
    "    for x, y in zip(np.arange(len(inp)), att_scores.detach().cpu().numpy()[0]):\n",
    "        plt.text(x-score_label_shift, y+.005, s=f'{y:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "09c3a0f2-32c0-4c37-a106-61a5c3505c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepocessed string: лучшая клиника в которой я был\n",
      "Prediction 1.000\n",
      "0.42073405\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "review = \"Лучшая клиника в которой я был\"\n",
    "plot_and_predict(\n",
    "    review = review, \n",
    "    SEQ_LEN=len(review.split()),\n",
    "    model = model_concat\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b6d130-4b0a-4a06-842d-8dbdb4ccbf42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ab6f4aa-32c0-4082-a82e-d48425e368e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_concat.state_dict(), 'lstm_attention_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70562bcf-eb43-4a90-a22c-b4b139ea07c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c9284733-63d1-4a28-9403-979f83551ea2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'unsqueeze'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m----> 2\u001b[0m     out \u001b[38;5;241m=\u001b[39m model_concat(\u001b[43mpreprocessed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'unsqueeze'"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    out = model_concat(preprocessed.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee805551-ea5e-46ed-8037-75f31f09e9f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fad3fec-d6fb-4fe0-8c60-962abadb92cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da31ca9-281b-4c63-9168-d193fea19cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1081259-8ad6-4842-9df1-fef93ca6ccac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07145b24-3e5e-44b4-b78f-2167d4211eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba9b7ea-6c73-4cf6-a3f7-e0daacf9fe7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc07ddf-433f-41bc-b6f3-e92d400a20b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70e945-4716-43c6-aaa4-dbe35b967d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
